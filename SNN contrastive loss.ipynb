{"cells":[{"cell_type":"markdown","metadata":{"id":"EshNz9H4iiJO"},"source":["##Introduzione  \n","Le reti siamesi sono reti neurali che condividono pesi tra due o più reti sorelle, ciascuna producendo vettori di incorporamento dei rispettivi input. Nell'apprendimento supervisionato per similarità, le reti vengono quindi addestrate per massimizzare il contrasto (distanza) tra incorporamenti di input di classi diverse, riducendo al minimo la distanza tra incorporamenti di classi simili, risultando in spazi di incorporamento che riflettono la segmentazione di classe degli input di formazione."]},{"cell_type":"markdown","metadata":{"id":"G44AOmUzi4vr"},"source":["##Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_KAksdSKNROD"},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from pathlib import Path\n","from tensorflow.python.ops.gen_array_ops import concat_v2_eager_fallback\n","from imutils import build_montages\n","from tensorflow.python.ops.numpy_ops import np_config\n","np_config.enable_numpy_behavior()\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","epochs = 100\n","margin = 1 #Margine per la perdità di contrasto."]},{"cell_type":"markdown","metadata":{"id":"kz3YT-7DjK8x"},"source":["##Creare i dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WYRLHceEFHm5"},"outputs":[],"source":["no_mask_train_ds = tf.keras.utils.image_dataset_from_directory(\n","  '/content/drive/Shareddrives/GRUPPI_CIMMINO/Aliberti/Datasets/NoMaskDataset',\n","  validation_split=0.5,\n","  subset=\"training\",\n","  seed=123,\n","  image_size=(130, 130),\n","  batch_size=215\n","  )\n","\n","no_mask_val_ds = tf.keras.utils.image_dataset_from_directory(\n","  '/content/drive/Shareddrives/GRUPPI_CIMMINO/Aliberti/Datasets/NoMaskDataset',\n","  validation_split=0.5,\n","  subset=\"validation\",\n","  seed=123,\n","  image_size=(130, 130),\n","  batch_size=215\n","  )\n","\n","mask_ds = tf.keras.utils.image_dataset_from_directory(\n","  '/content/drive/Shareddrives/GRUPPI_CIMMINO/Aliberti/Datasets/MaskDataset',\n","  validation_split=0.5,\n","  subset=\"training\",\n","  seed=123,\n","  image_size=(130, 130),\n","  batch_size= 215\n","  )"]},{"cell_type":"markdown","metadata":{"id":"iHwoDLFYjbS2"},"source":["##Creare coppie di immagini  \n","Formeremo il modello per differenziare tra immagini di soggetti diversi. Per il momento utilizzeremo solo immagini di soggetti senza mascherina. Ad esempio, l'immagine appartenente al soggetto 1 deve essere differenziata dal resto delle immagini di altri soggetti (da 2 a 43), l'immagine del soggetto 2 differente dal soggetto 1 e da 3 a 43 e così via. Per fare ciò, selezioneremo N immagini casuali dalla classe A (ad esempio, per il soggetto 1) e le abbineremo a N immagini casuali di un'altra classe B (ad esempio, per il soggetto 2). Quindi, possiamo ripetere questo processo per tutte le classi di soggetti (fino al soggetto 43). Dopo aver accoppiato il soggetto 1 con altri soggetti, possiamo ripetere questo processo per le classi rimanenti per il resto dei soggetti (da 2 a 43)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xC2c2aYaczwE"},"outputs":[],"source":["def make_pairs(images, labels):\n","\t# initialize two empty lists to hold the (image, image) pairs and labels to indicate if a pair is positive or negative\n","\tpairImages = []\n","\tpairLabels = []\n","  # calculate the total number of classes present in the dataset and then build a list of indexes for each class label that provides the indexes for all examples with a given label\n","\tnumClasses = len(np.unique(labels))\n","\tidx = [np.where(labels == i)[0] for i in range(0, numClasses)]\n","  # loop over all images\n","\tfor idxA in range(len(images)):\n","\t\t# grab the current image and label belonging to the current iteration\n","\t\tcurrentImage = images[idxA]\n","\t\tlabel = labels[idxA]\n","\t\t# randomly pick an image that belongs to the *same* class label\n","\t\tidxB = np.random.choice(idx[label])\n","\t\tposImage = np.array(images)[idxB]\n","\t\t# prepare a positive pair and update the images and labels lists, respectively\n","\t\tpairImages.append([currentImage, posImage])\n","\t\tpairLabels.append(1)\n","  \t# grab the indices for each of the class labels *not* equal to the current label and randomly pick an image corresponding to a label *not* equal to the current label\n","\t\tnegIdx = np.where(labels != label)[0]\n","\t\tnegImage = images[np.random.choice(negIdx)]\n","\t\t# prepare a negative pair of images and update our lists\n","\t\tpairImages.append([currentImage, negImage])\n","\t\tpairLabels.append(0)\n","\t# return a 2-tuple of our image pairs and labels\n","\treturn (np.array(pairImages), np.array(pairLabels))\n"," \n","# load dataset\n","print(\"[INFO] Loading dataset...\")\n","(trainX, trainY), (testX, testY) = no_mask_train_ds\n","trainX = trainX.astype(\"float32\")\n","testX = testX.astype(\"float32\")\n","(valX, valY), (testValX, testValY) = no_mask_val_ds\n","valX = valX.astype(\"float32\")\n","\n","# build the positive and negative image pairs\n","print(\"[INFO] Preparing positive and negative pairs...\")\n","\n","(pairTrain, labelTrain) = make_pairs(trainX, trainY)\n","print(\"[INFO] Completed Train...\")\n","\n","(pairVal, labelVal) = make_pairs(valX, valY)\n","print(\"[INFO] Completed Validation...\")\n","\n","(pairTest, labelTest) = make_pairs(testX, testY)\n","print(\"[INFO] Completed Test...\")"]},{"cell_type":"markdown","metadata":{"id":"Sa5qLee_lSnt"},"source":["##Dividere le coppie di training, le coppie di validation e le coppie di test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NrTY9LFKKCt0"},"outputs":[],"source":["x_train_1 = pairTrain[:, 0]  # x_train_1.shape is (430, 130, 130)\n","x_train_2 = pairTrain[:, 1]\n","\n","x_val_1 = pairVal[:, 0]  # x_val_1.shape = (430, 130, 130)\n","x_val_2 = pairVal[:, 1]\n","\n","x_test_1 = pairTest[:, 0]  # x_test_1.shape = (430, 130, 130)\n","x_test_2 = pairTest[:, 1]"]},{"cell_type":"markdown","metadata":{"id":"vn8fNyHpl7vV"},"source":["##Visualizzare le coppie e le loro etichette"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CRp6ycldN3y1"},"outputs":[],"source":["def visualize(pairs, labels, to_show=6, num_col=3, predictions=None, test=False):\n","    \"\"\"Creates a plot of pairs and labels, and prediction if it's test dataset.\n","\n","    Arguments:\n","        pairs: Numpy Array, of pairs to visualize, having shape\n","               (Number of pairs, 2, 130, 130).\n","        to_show: Int, number of examples to visualize (default is 6)\n","                `to_show` must be an integral multiple of `num_col`.\n","                 Otherwise it will be trimmed if it is greater than num_col,\n","                 and incremented if if it is less then num_col.\n","        num_col: Int, number of images in one row - (default is 3)\n","                 For test and train respectively, it should not exceed 3 and 7.\n","        predictions: Numpy Array of predictions with shape (to_show, 1) -\n","                     (default is None)\n","                     Must be passed when test=True.\n","        test: Boolean telling whether the dataset being visualized is\n","              train dataset or test dataset - (default False).\n","\n","    Returns:\n","        None.\n","    \"\"\"\n","\n","    # Define num_row\n","    # If to_show % num_col != 0\n","    #    trim to_show,\n","    #       to trim to_show limit num_row to the point where\n","    #       to_show % num_col == 0\n","    #\n","    # If to_show//num_col == 0\n","    #    then it means num_col is greater then to_show\n","    #    increment to_show\n","    #       to increment to_show set num_row to 1\n","    num_row = to_show // num_col if to_show // num_col != 0 else 1\n","\n","    # `to_show` must be an integral multiple of `num_col`\n","    #  we found num_row and we have num_col\n","    #  to increment or decrement to_show\n","    #  to make it integral multiple of `num_col`\n","    #  simply set it equal to num_row * num_col\n","    to_show = num_row * num_col\n","\n","    # Plot the images\n","    fig, axes = plt.subplots(num_row, num_col, figsize=(5, 5))\n","    for i in range(to_show):\n","\n","        # If the number of rows is 1, the axes array is one-dimensional\n","        if num_row == 1:\n","            ax = axes[i % num_col]\n","        else:\n","            ax = axes[i // num_col, i % num_col]\n","\n","        ax.imshow(tf.concat([pairs[i][0], pairs[i][1]], axis=1), cmap=\"gray\")\n","        ax.set_axis_off()\n","        if test:\n","            ax.set_title(\"True: {} | Pred: {:.5f}\".format(labels[i], predictions[i][0]))\n","        else:\n","            ax.set_title(\"Label: {}\".format(labels[i]))\n","    if test:\n","        plt.tight_layout(rect=(0, 0, 5, 5), w_pad=0.0)\n","    else:\n","        plt.tight_layout(rect=(0, 0, 5, 5))\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"rhDyDfBkmQEs"},"source":["#Ispezionare le coppie di training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Sluns1_J9nD"},"outputs":[],"source":["visualize(pairTrain.astype('uint8'), labelTrain.astype('uint8'), to_show=3, num_col=3)"]},{"cell_type":"markdown","metadata":{"id":"b5L1PukPmISF"},"source":["##Ispezionare le coppie di validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GGLvKwZ7PSXd"},"outputs":[],"source":["visualize(pairVal.astype('uint8'), labelVal.astype('uint8'), to_show=3, num_col=3)"]},{"cell_type":"markdown","metadata":{"id":"4lpcnNzKmVij"},"source":["##Ispezionare le coppie di test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bNEX8e5OPVTt"},"outputs":[],"source":["visualize(pairTest.astype('uint8'), labelTest.astype('uint8'), to_show=3, num_col=3)"]},{"cell_type":"markdown","metadata":{"id":"OKbfSLdkmc-4"},"source":["##Definire il modello  \n","Ci sono due livelli di input, ciascuno che porta alla propria rete, che produce incorporamenti. Un livello Lambda li unisce quindi utilizzando una distanza euclidea e l'output unito viene inviato alla rete finale."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TxGHeWXWc5k9"},"outputs":[],"source":["# Provided two tensors t1 and t2\n","# Euclidean distance = sqrt(sum(square(t1-t2)))\n","def euclidean_distance(vects):\n","    \"\"\"Find the Euclidean distance between two vectors.\n","\n","    Arguments:\n","        vects: List containing two tensors of same length.\n","\n","    Returns:\n","        Tensor containing euclidean distance\n","        (as floating point value) between vectors.\n","    \"\"\"\n","\n","    x, y = vects\n","    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n","    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n","\n","\n","input = layers.Input((130, 130, 3))\n","x = tf.keras.layers.BatchNormalization()(input)\n","x = layers.Conv2D(4, (5, 5), activation=\"tanh\")(x)\n","x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n","x = layers.Conv2D(16, (5, 5), activation=\"tanh\")(x)\n","x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n","x = layers.Flatten()(x)\n","\n","x = tf.keras.layers.BatchNormalization()(x)\n","x = layers.Dense(10, activation=\"tanh\")(x)\n","embedding_network = keras.Model(input, x)\n","\n","\n","input_1 = layers.Input((130, 130, 3))\n","input_2 = layers.Input((130, 130, 3))\n","\n","# As mentioned above, Siamese Network share weights between\n","# tower networks (sister networks). To allow this, we will use\n","# same embedding network for both tower networks.\n","tower_1 = embedding_network(input_1)\n","tower_2 = embedding_network(input_2)\n","\n","merge_layer = layers.Lambda(euclidean_distance)([tower_1, tower_2])\n","normal_layer = tf.keras.layers.BatchNormalization()(merge_layer)\n","output_layer = layers.Dense(1, activation=\"sigmoid\")(normal_layer)\n","siamese = keras.Model(inputs=[input_1, input_2], outputs=output_layer)"]},{"cell_type":"markdown","metadata":{"id":"78VJRLlQmn3d"},"source":["##Definire la perdita di contrasto\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-sQmkRu4dNAg"},"outputs":[],"source":["def loss(margin=1):\n","    \"\"\"Provides 'constrastive_loss' an enclosing scope with variable 'margin'.\n","\n","  Arguments:\n","      margin: Integer, defines the baseline for distance for which pairs\n","              should be classified as dissimilar. - (default is 1).\n","\n","  Returns:\n","      'constrastive_loss' function with data ('margin') attached.\n","  \"\"\"\n","\n","    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n","    #                         true_value * square( max(margin-prediction, 0) ))\n","    def contrastive_loss(y_true, y_pred):\n","        \"\"\"Calculates the constrastive loss.\n","\n","      Arguments:\n","          y_true: List of labels, each label is of type float32.\n","          y_pred: List of predictions of same length as of y_true,\n","                  each label is of type float32.\n","\n","      Returns:\n","          A tensor containing constrastive loss as floating point value.\n","      \"\"\"\n","\n","        square_pred = tf.math.square(y_pred)\n","        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n","        return tf.math.reduce_mean(\n","            (1 - y_true) * square_pred + (y_true) * margin_square\n","        )\n","\n","    return contrastive_loss"]},{"cell_type":"markdown","metadata":{"id":"tzeTBqpZmyf9"},"source":["##Compilare il modello con la perdita di contrasto"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EFWSyQMDdQT3"},"outputs":[],"source":["siamese.compile(loss=loss(margin=margin), optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n","siamese.summary()"]},{"cell_type":"markdown","metadata":{"id":"DbD9Sr6qm_3M"},"source":["##Addestrare il modello"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"spmJu8eRdWce"},"outputs":[],"source":["history = siamese.fit(\n","    [x_train_1, x_train_2],\n","    labelTrain,\n","    validation_data=([x_test_1, x_test_2], labelVal),\n","    #batch_size=64,\n","    epochs=10\n",")"]},{"cell_type":"markdown","metadata":{"id":"sDf486o7nLwZ"},"source":["##Visualizzare i risultati"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZwllE_PVasF"},"outputs":[],"source":["def plt_metric(history, metric, title, has_valid=True):\n","    \"\"\"Plots the given 'metric' from 'history'.\n","\n","    Arguments:\n","        history: history attribute of History object returned from Model.fit.\n","        metric: Metric to plot, a string value present as key in 'history'.\n","        title: A string to be used as title of plot.\n","        has_valid: Boolean, true if valid data was passed to Model.fit else false.\n","\n","    Returns:\n","        None.\n","    \"\"\"\n","    plt.plot(history[metric])\n","    if has_valid:\n","        plt.plot(history[\"val_\" + metric])\n","        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n","    plt.title(title)\n","    plt.ylabel(metric)\n","    plt.xlabel(\"epoch\")\n","    plt.show()\n","\n","\n","# Plot the accuracy\n","plt_metric(history=history.history, metric=\"accuracy\", title=\"Model accuracy\")\n","\n","# Plot the constrastive loss\n","plt_metric(history=history.history, metric=\"loss\", title=\"Constrastive Loss\")"]},{"cell_type":"markdown","metadata":{"id":"UmAD1fu_nUdR"},"source":["##Valutare il modello"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jB-GY18dVeiB"},"outputs":[],"source":["results = siamese.evaluate([x_test_1, x_test_2], labelTest)\n","print(\"test loss, test acc:\", results)"]},{"cell_type":"markdown","metadata":{"id":"BLJRamzmnd45"},"source":["##Visualizzare le previsioni"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-8SqkgZ_Vh5N"},"outputs":[],"source":["predictions = siamese.predict([x_test_1, x_test_2])\n","visualize(pairTest.astype('uint8'), labelTest.astype('uint8'), to_show=4, predictions=predictions, test=True)"]},{"cell_type":"markdown","metadata":{"id":"55eTMPJtnwRT"},"source":["##Creare coppie finali di immagini\n","Formeremo il modello per differenziare immagini di stessi soggetti, ma con e senza mascherina. Ad esempio, l'immagine appartenente al soggetto 1, senza mascherina, deve essere differenziata dall'immagine del soggetto 1, con mascherina, l'immagine del soggetto 2, senza mascherina, differente dal soggetto 2, con mascherina, e così via. Per fare ciò, selezioneremo 1 immagine dalla classe A (ad esempio, per il soggetto 1 senza mascherina) e l'abbiniamo a una immagine di un'altra classe B (ad esempio, per il soggetto 1 con mascherina). Quindi, possiamo ripetere questo processo per tutte le classi di soggetti (fino al soggetto 43). Dopo aver accoppiato il soggetto 1 senza mascherina, con il soggetto 1 con mascherina, possiamo ripetere questo processo per le classi rimanenti per il resto dei soggetti (da 2 a 43)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvMKkOUppZ-i"},"outputs":[],"source":["def make_final_pairs(images, labels):\n","\t# initialize two empty lists to hold the (image, image) pairs and labels to indicate the number of class\n","\tpairImages = []\n","\tpairLabels = []\n","  # calculate the total number of classes present in the dataset\n","\tnumClasses = len(np.unique(labels))\n","\t# loop for the total number of classes\n","\tfor idxA in range(numClasses):\n","\t\t# loop over all images\n","\t\tfor idxC in range(len(images)):\n","\t\t\t# grab the current image and label belonging to the current iteration\n","\t\t\tif labels[idxC] == idxA:\n","\t\t\t\tcurrentImage = images[idxC]\n","\t\t\t\tlabel = labels[idxC]\n","\t\t\t\t# loop over all images following the current image\n","\t\t\t\tfor idxB in range(idxC + 1, len(images)):\n","\t\t\t\t\t# pick an image that belongs to the * same * subject class label with / without mask \n","\t\t\t\t\tif labels[idxB] == label:\n","\t\t\t\t\t\tposImage = np.array(images)[idxB]\n","\t\t\t\tbreak\n","\t\t# prepare pair and update the images and labels lists, respectively\n","\t\tpairImages.append([currentImage, posImage])\n","\t\tpairLabels.append(label)\n","\t# return a 2-tuple of our image pairs and labels\n","\treturn (np.array(pairImages), np.array(pairLabels))\n"," \n","# load dataset\n","print(\"[INFO] Loading dataset...\")\n","(trainA, trainB), (testA, testB) = mask_ds\n","testA = testA.astype(\"float32\")\n","\n","resultX = tf.concat(axis=0, values = [testA, testX])\n","resultY = tf.concat(axis=0, values = [testB, testY])\n","\n","# build the image pairs\n","print(\"[INFO] Preparing pairs...\")\n","(pairResult, labelResult) = make_final_pairs(resultX, resultY)\n","print(\"[INFO] Completed result...\")"]},{"cell_type":"markdown","metadata":{"id":"XdYnJlcnnxvx"},"source":["##Ispezionare le coppie finali di result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rkqCZ6k89KJE"},"outputs":[],"source":["visualize(pairResult.astype('uint8'), labelResult.astype('uint8'), to_show=2, num_col=3)"]},{"cell_type":"markdown","metadata":{"id":"IlSSSKRCn4OK"},"source":["##Dividere le coppie di result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3cfumN7a8yog"},"outputs":[],"source":["x_result_1 = pairResult[:, 0]  # x_result_1.shape is (43, 130, 130, 3)\n","x_result_2 = pairResult[:, 1]"]},{"cell_type":"markdown","metadata":{"id":"ThjiEWoDn4nZ"},"source":["##Visualizzare le previsioni di result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jKUm4EDABhmR"},"outputs":[],"source":["predictions = siamese.predict([x_result_1, x_result_2])\n","visualize(pairResult.astype('uint8'), labelResult.astype('uint8'), to_show=43, num_col=4, predictions=predictions, test=True)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyPfxFVGyT8am4Bgd7pF5DJK"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}